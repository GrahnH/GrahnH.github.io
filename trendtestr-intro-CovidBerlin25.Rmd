---
title: "trendtestr-intro-CovidBerlin25"
subtitle: "Complete Automated Analysis Pipeline"
output: 
  rmarkdown::html_document:
    theme: lumen
    highlight: tango
    toc: true
    toc_float: 
      collapsed: true
      smooth_scroll: true
    toc_depth: 3
    code_folding: show
    fig_width: 10
    fig_height: 6
    fig_caption: true
vignette: >
  %\VignetteIndexEntry{trendtestr-intro-CovidBerlin25}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

## Quick Start Guide

> This vignette demonstrates a **complete automated workflow** in **`trendtestR`** using the open resource **`COVID-19 in Berlin, Fallzahlen und Indikatoren-Gesamtuebersicht`** dataset.\

### Workflow Overview

1.  **Data Import & Exploration** → `plot_weekly_cases()`
2.  **Multi-granularity Comparison** → `compare_monthly_cases()`
3.  **Automated Statistical Testing** → `run_group_tests()`
4.  **Automated Trend Model Fitting** → `explore_trend_auto()`
5.  **Time Series Diagnostics** → `check_rate_diff_arima_ready()`

### Workflow Details

The goal of this vignette is to demonstrate how `trendtestR` can be applied to a real-world dataset. The workflow illustrates a typical exploratory data analysis (EDA) pipeline for epidemiological or public-health trend data:

1.  **Initial exploration and visualization** — plotting raw counts to observe general temporal trends.\
2.  **Cross-year comparisons at multiple granularities** — comparing selected periods (e.g., winter months) both weekly and daily.\
3.  **Automatic group testing** — applying `run_group_tests()` to select appropriate statistical tests under the hood, while reporting assumptions and effect sizes.\
4.  **Automatic trend fitting** — using `explore_trend_auto()` to automatically select model family and smoothing, enabling rapid model exploration.\
5.  **(Optional) ARIMA readiness check** — running diagnostic checks to determine whether the time series fulfills basic stationarity and variability conditions for ARIMA modeling. A **verification of time-window continuity** is recommended.

## Data Source

The data used in this vignette are provided by the [Open Data Portal Berlin](https://www.berlin.de/lageso/gesundheit/infektionskrankheiten/corona/tabelle-indikatoren-gesamtuebersicht/index.php/index/all.csv), with License Creative Commons Attribution (cc-by).\
Last accessed on 04 June 2025.

# Workflow

## Required Packages and Data Import

```{r message=FALSE, warning=FALSE}
library(trendtestR)
library(rio)
library(readr)
library(dplyr)
library(lubridate)
library(ggplot2)
```

```{r paged.print=FALSE}
indexbc <- import("index.csv")
glimpse(indexbc)
```

## First Exploration with `plot_weekly_cases()`

The function `plot_weekly_cases()` provides a convenient entry point for epidemiology-style weekly visualization. The function aggregates cases by ISO week within a user-defined retrospective window, produces three types of plots, and reports 95% confidence intervals for weekly means. 
In this workflow, it is used to display the weekly trend of new cases over the most recent 26 weeks.

```{r plot weekly cases,fig.align='center', fig.cap="Weekly Berlin COVID-19 trends", results="hold"}
plot_weekly_cases(indexbc,
                  datum_col = "datum", 
                  value_col = "neue_faelle",
                  agg_fun = "sum", 
                  weeks_back = c(1,26), 
                  save_plot = FALSE)
```

## Multi-granularity Cross-year Comparison with `compare_monthly_cases()`

### Basic Using of `compare_monthly_cases()`
The function `compare_monthly_cases()` provides a convenient entry point for cross-year comparisons of numeric variables such as new case numbers. It supports aggregation by day or ISO week, optional cross-year logic, automated visualization (trend line, dot plot, boxplot), and group-wise faceting. Appropriate statistical tests (e.g., t-test, ANOVA) are automatically selected and executed.
In this workflow, it is applied to compare monthly new cases in daily granularity between November 2022 and October 2024 (treated as years 2023 and 2024), with results expressed at the monthly scale.

```{r comepare daily, fig.align='center', fig.cap="Monthly Comparison Berlin COVID-19 data", message=TRUE, warning=FALSE, results="hold"}
resday<- compare_monthly_cases(
  indexbc,
  datum_col = "datum",
  value_col = "neue_faelle",
  years = c(2023,2024),
  months = c(11:12, 1:10),
  granularity = "day",
  agg_fun = "sum",
  shift_month = "mth_to_next"
)

```

```{r include=FALSE, results="hold"}
resweek<- compare_monthly_cases(
  indexbc,
  datum_col = "datum",
  value_col = "neue_faelle",
  years = c(2023,2024),
  months = c(11:12, 1:10),
  granularity = "week",
  agg_fun = "sum",
  shift_month = "mth_to_next"
)

resinzweek<- compare_monthly_cases(
  indexbc,
  datum_col = "datum",
  value_col = "7_tage_inzidenz",
  years = c(2022,2023,2024),
  months = c(11:12, 1:10),
  granularity = "week",
  agg_fun = "mean",
  shift_month = "mth_to_next"
)

```

At the same time, to showcase subsequent workflow features, several alternative analyses with different parameter settings were prepared at this step.

```{r eval=FALSE, results="hold"}
# Same analysis at weekly level
resweek <- compare_monthly_cases(
  indexbc,
  value_col = "neue_faelle",
  years = c(2023,2024),
  months = c(11:12, 1:10),
  agg_fun = "sum",
  granularity = "week",  # Only parameter change needed
  shift_month = "mth_to_next"
)

# Same analysis at weekly level with more than two years of continuous data
resinzweek<- compare_monthly_cases(
  indexbc,
  datum_col = "datum",
  value_col = "7_tage_inzidenz",
  years = c(2022,2023,2024),
  months = c(11:12, 1:10),
  granularity = "week",
  agg_fun = "mean",
  shift_month = "mth_to_next"
)

```
### Distribution Comparsion with `compare_distribution_by_granularity`  

At this step, if the data are processed at different levels of granularity, the function `compare_distribution_by_granularity` enables QQ plots and normality assessments, helping to determine which granularity is more appropriate for subsequent statistical testing and model fitting.

```{r, fig.align='center', fig.cap="Multi-granularity distribution Comparison", results="hold"}
compare_distribution_by_granularity(res_day = resday, res_week = resweek )
```

## Automatic Group Testing with `run_group_tests()`

The function run_group_tests() provides a convenient entry point for conducting automated group-wise statistical tests. The function determines the choice of statistical test primarily by the number of groups in the data.

### Integrating with `compare_monthly_cases()`

**Default grouping**:\
If no explicit grouping variable is specified, the function defaults to grouping by **year**. This is particularly useful for datasets, where annual comparisons are the natural first step.

**Direct use after preprocessing**:\
For data that have already been aggregated and cleaned using `compare_monthly_cases()`, the resulting object can be passed directly to `run_group_tests()`. This avoids manual reshaping and ensures consistency across the workflow.

### Calling Results from `compare_monthly_cases()`

When `compare_monthly_cases()` is executed, it not only aggregates the data but also performs the relevant group tests internally. The results are stored in the \$tests element of the returned object. In typical use cases, these results can be directly called without the need to rerun the testing function.

```{r,results="hold"}
resweek$tests
```

Since the original dataset is relatively large, the following demonstrations continue to use the preprocessed data returned by `compare_monthly_cases()`.

### Assigning Models for Count Data

When the data variable is of count type, the function automatically determines whether a Poisson or Negative Binomial framework is more appropriate, based on the dispersion of the data.

For cases where the data are confirmed to follow a Poisson or Negative Binomial distribution, the functions `run_count_two_group_tests()` or `run_count_multi_group_tests()` can be used, allowing the parameter **phi** to be modified in order to inspect more detailed results.

```{r, results="hold"}
run_group_tests(resday$data, 
                value_col = ".value",
                group_col = "jahr")
```

### General Testing Strategy

The function determines the appropriate statistical test primarily by the number of groups in the data:

**Two groups** : pairwise testing (with parametric vs. non-parametric options, and optional paired design).

**More than two groups** : multi-group testing (with parametric vs. non-parametric options). Within each branch, distributional assumptions (normality, variance homogeneity) decide whether a parametric or non-parametric test is applied.

```{r, results="hold"}
run_group_tests(resinzweek$data, 
                value_col = ".value",
                group_col = "jahr", 
                alpha = 0.1)
```

When the argument `paired = TRUE` is set but the group sizes differ, the function automatically prevents paired testing and returns an informative error message. This safeguards against misinterpretation and guides the user towards an appropriate unpaired test.

```{r, results="hold"}
run_group_tests(resweek$data, paired =TRUE)
```

## Automatic Trend Fitting with `explore_trend_auto()`

This function is designed to assist users in exploring **temporal trends** with flexible regression models.

Depending on the data type, it automatically selects an appropriate family (e.g. Gaussian GLM for continuous data, Poisson/Negative Binomial/Zero-Inflated models for count data). Natural splines (`splines::ns`) are used to capture non-linear shapes over time. In the workflow, **year** can be specified as a grouping factor, so that interaction terms allow direct comparison of trend shapes across years, offering an additional perspective for visualizing inter-annual differences.

### Automatic Model Fitting for Count Data

After determining the data type, the function assigns a Poisson/Negative Binomial GAM for standard count data.

Following the usual Poisson modeling workflow, if overdispersion is detected and both Poisson and Negative Binomial models converge, their AIC values are compared and the model with the lower AIC is selected. If only one model converges, that model is returned; if neither converges, the function reports a model fitting failure.

When the dataset exhibits zero-inflation, the function either reads this information (from prior preprocessing) or detects it internally. In this case, it dispatches to the zero-inflated model family (pscl::zeroinfl()), where a Zero-Inflated Negative Binomial (ZINB) model is fitted as the most appropriate choice.

In this workflow, the daily incidence dataset was modeled using such a zero-inflated specification.

```{r, results="hold"}
explore_trend_auto(resday$data, datum_col= "datum", value_col=".value", group_col = "jahr",family = "auto", kdf = 2)
```

### Automatic Model Fitting for Continuous Data

After determining the data type, the function assigns a Gaussian/Gamma GLM for continuous data.

If both Gaussian and Gamma models converge, their AIC values are compared and the model with the lower AIC is selected.If only one model converges, that model is returned; if neither converges, the function reports a model fitting failure.

In this workflow, the 7-day incidence dataset was modeled using a Gamma GLM as the most appropriate specification. **NOTE:** In the current version, all data types other than those explicitly inferred as count (including zero-inflated) are dispatched to GLM-based modeling.

```{r, results="hold"}
explore_trend_auto(resinzweek$data, datum_col= "datum", value_col=".value", group_col = "jahr", family = "auto", kdf = 4)
```

### Direct Use of Underlying Modeling Functions

The function `explore_trend_auto()`records in its output which concrete modeling function was used, accessible under the `$used_function` field.\
In the current version include:

-   `explore_poisson_trend`

-   `explore_zinb_trend`

-   `explore_continuous_trend`

For users with specific requirements—such as adjusting the `phi` parameter, forcing a particular distribution family, or inspecting a **Vuong test** when comparing ZIP and ZINB models—these underlying functions can be executed directly.

``` r
explore_poisson_trend(resweek$data, datum_col= "datum", value_col=".value", group_col = "jahr",family = "auto", k_spline = 3, phi = 1)

explore_zinb_trend(resday$data, datum_col= "datum", value_col=".value", group_col = "jahr", family = "auto", k_spline =3, return_formula = FALSE, verbose = FALSE, control = 200, run_vuong = TRUE)

explore_continuous_trend(resinzweek$data, datum_col= "datum", value_col=".value", group_col = "jahr", family = "auto", df_spline = 6)
```

### Model Diagnostics with `diagnose_model_trend()`

After fitting the trend model, running `diagnose_model_trend()` constitutes a required step in the workflow. The function produces diagnostic plots (residuals vs fitted, QQ-plot, scale–location) and statistical tests to assess model adequacy. For **GLMs/GAMs**, **deviance** residuals are reported by default. In contrast, for **zero-inflated models** deviance residuals are not consistently defined, and the function switches to **response** residuals instead.

In this workflow, 7-day incidence dataset was evaluated using **deviance** residuals, while the daily incidence dataset for zero-inflated models the function defaults to **response** residuals.

```{r message=FALSE, warning=FALSE, include=FALSE, results="hold"}
daymodel <- explore_trend_auto(resday$data, datum_col= "datum", value_col=".value", group_col = "jahr",family = "auto", kdf = 2)

weekinzmodel <- explore_trend_auto(resinzweek$data, datum_col= "datum", value_col=".value", group_col = "jahr", family = "auto", kdf = 4)

```

``` r
daymodel <- explore_trend_auto(resday$data, datum_col= "datum", value_col=".value", group_col = "jahr",family = "auto", kdf = 2)

weekinzmodel <- explore_trend_auto(resinzweek$data, datum_col= "datum", value_col=".value", group_col = "jahr", family = "auto", kdf = 4)
```

#### Model Diagnostics for GLMs/GAMs

```{r echo=TRUE, fig.align='center', fig.cap="Diagnose result plots of GLMs/GAMs", message=FALSE, warning=FALSE, results="hold"}
diagnose_model_trend(weekinzmodel$model)
```

#### Model Diagnostics Zero-inflated Models

```{r echo=TRUE,  fig.align='center', fig.cap="Diagnose result plots of zero-inflated models", message=FALSE, warning=FALSE, results="hold"}
diagnose_model_trend(daymodel$model)
```

## Additional ARIMA Modeling Preparation Checking with `check_rate_diff_arima_ready()`

Typically, time-series analysis proceeds from exploratory data inspection to more detailed modeling. In this workflow, trendtestR provides a bridging function to prepare datasets intended for subsequent ARIMA modeling.

First, `check_continuity_by_window()` verifies whether the selected time interval is continuous and highlights potential gaps, supporting precise adjustments of the time window. Next, `check_rate_diff_arima_ready()` assesses whether the data meets key time-series assumptions. This step examines outliers, trend, and seasonality patterns, and evaluates whether differencing is required, thereby ensuring a more stable ARIMA fit.

```{r echo=TRUE, message=FALSE, warning=FALSE, results="hold"}
result <- check_continuity_by_window(date_vec = resinzweek$data$datum, years = c(2023,2024),
                                     months = c(11,5), window_unit = "week", 
                                     use_isoweek = TRUE, allow_leading_gap = TRUE)

result$continuous

result$gaps
```

```{r echo=TRUE, message=TRUE, warning=TRUE, results="hold"}
check_rate_diff_arima_ready(
  rate_diff_vec = resinzweek$data$.value,
  date_vec = resinzweek$data$datum,
  frequency = 13,
  plot_acf = TRUE,
  do_stl = TRUE,
)
```

# Summary

This vignette illustrated the use of **`trendtestR`** with the Berlin COVID-19 dataset through a structured exploratory workflow.\
We began with **initial visualization** of temporal patterns, followed by **cross-year comparisons at multiple granularities**.\
Next, we applied **automatic group testing** with `run_group_tests()` to assign appropriate parametric or non-parametric tests.\
Building on this, we performed **automatic trend fitting** with `explore_trend_auto()`, where model diagnostics were carried out as the final step of the fitting process.\
Finally, we demonstrated the **ARIMA readiness check**, which integrates continuity validation and assesses stationarity and variability conditions.

Together, these steps show how `trendtestR` supports a coherent pipeline from visualization and statistical testing to model fitting and time-series preparation in public-health data analysis.

## Comparison with Companion Vignette **`trendtestR-intro-eustockmarkets`**

Compared to the companion vignette **`trendtestR-intro-eustockmarkets`**, the workflow here follows a very similar structure: we start with exploratory visualization, proceed to continuity checks, and then move on to statistical testing and trend fitting.

The key difference lies in the data handling steps.\
- In the **EUStockMarkets** example, the vignette demonstrates how to **reshape and convert time-series objects** into a tidy format suitable for analysis.\
- In contrast, the **Berlin COVID-19 dataset** is already provided in a straightforward tabular structure, so **no format conversion is required**.

Instead, this vignette emphasizes an **additional trend plotting step** at the beginning, to highlight raw temporal dynamics before statistical procedures are applied. This allows the analysis to more closely mirror a typical public-health EDA workflow.

For further details, see the companion vignette trendtestR-intro-eustockmarkets and the package documentation.
